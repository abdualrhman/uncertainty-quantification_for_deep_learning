{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "from src.utils.cp_utils import * \n",
    "from src.models.conformal_model import ConformalModel, ConformalModelLogits\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "from src.data.make_cifar10_dataset import CIFAR10, get_img_transformer\n",
    "from src.models.cifar10_conv_model import Cifar10ConvModel\n",
    "\n",
    "from src.utils.bootstrap_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_dataset = CIFAR10(split=\"train\", root='../data/processed', download=True,\n",
    "                      transform=get_img_transformer())\n",
    "test_dataset = CIFAR10(split=\"test\", root='../data/processed', download=True,\n",
    "                      transform=get_img_transformer())\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=32)\n",
    "calib_dataset = CIFAR10(split=\"calib\", root='../data/processed', download=True,\n",
    "                      transform=get_img_transformer())\n",
    "calib_dataloader = torch.utils.data.DataLoader(\n",
    "        calib_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Cifar10ConvModel()\n",
    "model1.load_state_dict(torch.load(\"../models/trained_model.pt\"))\n",
    "model1.eval()\n",
    "model1 = torch.nn.DataParallel(model1).cpu()\n",
    "model2 = Cifar10ConvModel()\n",
    "model2.load_state_dict(torch.load(\"../models/trained_model.pt\"))\n",
    "model2.eval()\n",
    "model2 = torch.nn.DataParallel(model2).cpu()\n",
    "model3 = Cifar10ConvModel()\n",
    "model3.load_state_dict(torch.load(\"../models/trained_model.pt\"))\n",
    "model3.eval()\n",
    "model3 = torch.nn.DataParallel(model3).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500     training accuracy: 0.7320625\n",
      "Step 1000    training accuracy: 0.77625\n",
      "Step 1500    training accuracy: 0.7749107142857142\n",
      "Step 2000    training accuracy: 0.806171875\n",
      "Step 2500    training accuracy: 0.8296875\n",
      "Step 3000    training accuracy: 0.8255208333333334\n",
      "Step 3500    training accuracy: 0.8332291666666667\n",
      "Step 4000    training accuracy: 0.8415234375\n",
      "Step 4500    training accuracy: 0.8605\n",
      "Step 5000    training accuracy: 0.8684375\n",
      "Step 5500    training accuracy: 0.8669196428571428\n",
      "Step 6000    training accuracy: 0.88453125\n",
      "Step 6500    training accuracy: 0.904375\n",
      "Step 7000    training accuracy: 0.9075520833333334\n",
      "Step 7500    training accuracy: 0.9140625\n",
      "Step 8000    training accuracy: 0.9146484375\n",
      "Step 500     training accuracy: 0.7211875\n",
      "Step 1000    training accuracy: 0.75859375\n",
      "Step 1500    training accuracy: 0.7598214285714285\n",
      "Step 2000    training accuracy: 0.79390625\n",
      "Step 2500    training accuracy: 0.8346875\n",
      "Step 3000    training accuracy: 0.81578125\n",
      "Step 3500    training accuracy: 0.826875\n",
      "Step 4000    training accuracy: 0.83234375\n",
      "Step 4500    training accuracy: 0.8535625\n",
      "Step 5000    training accuracy: 0.86140625\n",
      "Step 5500    training accuracy: 0.8708928571428571\n",
      "Step 6000    training accuracy: 0.892109375\n",
      "Step 6500    training accuracy: 0.90625\n",
      "Step 7000    training accuracy: 0.903125\n",
      "Step 7500    training accuracy: 0.9177083333333333\n",
      "Step 8000    training accuracy: 0.9130078125\n",
      "Step 500     training accuracy: 0.71525\n",
      "Step 1000    training accuracy: 0.770625\n",
      "Step 1500    training accuracy: 0.7654017857142857\n",
      "Step 2000    training accuracy: 0.7921875\n",
      "Step 2500    training accuracy: 0.819375\n",
      "Step 3000    training accuracy: 0.8131770833333334\n",
      "Step 3500    training accuracy: 0.8309375\n",
      "Step 4000    training accuracy: 0.83546875\n",
      "Step 4500    training accuracy: 0.84975\n",
      "Step 5000    training accuracy: 0.860625\n",
      "Step 5500    training accuracy: 0.8723214285714286\n",
      "Step 6000    training accuracy: 0.878671875\n",
      "Step 6500    training accuracy: 0.8859375\n",
      "Step 7000    training accuracy: 0.9009895833333333\n",
      "Step 7500    training accuracy: 0.9082291666666666\n",
      "Step 8000    training accuracy: 0.90984375\n"
     ]
    }
   ],
   "source": [
    "models = [model1, model2, model3]\n",
    "train_ensemble(models, train_dataset, print_acc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[8.1698e-08, 3.7372e-09, 3.4974e-06, 3.2972e-03, 2.6616e-10,\n",
      "          9.9670e-01, 1.8103e-07, 4.9945e-08, 7.8724e-08, 1.4190e-08]],\n",
      "\n",
      "        [[1.5091e-08, 2.4493e-06, 3.2369e-05, 9.6779e-01, 3.3871e-06,\n",
      "          3.1482e-02, 2.1535e-04, 2.0943e-04, 1.8057e-05, 2.4451e-04]],\n",
      "\n",
      "        [[1.4179e-06, 1.4989e-06, 9.7452e-04, 9.8571e-01, 1.8647e-04,\n",
      "          5.2205e-03, 6.4298e-03, 1.1243e-04, 5.2094e-06, 1.3585e-03]]])\n",
      "6.461454251862864e-07\n",
      "0.458948905909294\n"
     ]
    }
   ],
   "source": [
    "models = [model1, model2, model3]\n",
    "for inputs, targets in  test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        output = get_ensemble_preparation(models, inputs[0])\n",
    "        probs = torch.stack([nnf.softmax(x, dim=1) for x in output])\n",
    "        y1 = [r[:, 0].item() for r in probs]\n",
    "        y3 = [r[:, 3].item() for r in probs]\n",
    "        print(probs)\n",
    "        print(np.std(y1))\n",
    "        print(np.std(y3))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d685bfd7114377445cb2c23cc6bfca7f1f2544957139cb4a27ccab868339e3e1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
