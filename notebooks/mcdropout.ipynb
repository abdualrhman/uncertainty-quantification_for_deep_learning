{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import get_CIFAR10_img_transformer, validate_monte_carlo_prediction\n",
    "import torch \n",
    "from sklearn.metrics import f1_score\n",
    "from src.utils.utils import AverageMeter, coverage_size, get_monte_carlo_prediction_sets\n",
    "import torchvision\n",
    "from src.models.cifar10_conv_model import Cifar10ConvModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.CIFAR10(train=False, root='../data/processed', transform=get_CIFAR10_img_transformer())\n",
    "test_loader =torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cifar10ConvModel()\n",
    "model.load_state_dict(torch.load(\"../models/trained_conv_cifar10_model.pt\"))\n",
    "model.eval()\n",
    "model = torch.nn.DataParallel(model).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_monte_carlo_prediction(val_loader, predictions_sets):\n",
    "    \"\"\" Validate monte-carlor prediction sets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    val_loader : object\n",
    "        data loader object from the data loader module\n",
    "    predictions_sets : ArrayLike\n",
    "        monte-carlo prediction sets\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    coverage : float\n",
    "    set_size : float\n",
    "    f1_score : float\n",
    "    \"\"\"\n",
    "    size = AverageMeter('size')\n",
    "    coverage = AverageMeter('coverage')\n",
    "    f1_scores = AverageMeter('f1_scores')\n",
    "    pred_set_loader = torch.utils.data.DataLoader(predictions_sets, batch_size=val_loader.batch_size,shuffle=False, collate_fn=lambda x: x)\n",
    "    for S, (_, y) in zip(pred_set_loader, val_loader):\n",
    "        top1s = []\n",
    "        [top1s.append(p_set[0]) for p_set in S]\n",
    "        S_tensor = [torch.tensor(sublist) for sublist in S]\n",
    "        cov, sz = coverage_size(S_tensor, y)\n",
    "        f1 = f1_score(y_true=y.detach().cpu(),\n",
    "                    y_pred=top1s, average='macro', zero_division=0)\n",
    "        coverage.update(cov)\n",
    "        size.update(sz)\n",
    "        f1_scores.update(f1)\n",
    "    return coverage.avg, size.avg, f1_scores.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_monte_carlo_prediction_sets(val_loader=test_loader, model=model, alpha=0.1, n_samples=len(test_set), n_classes=10, forward_passes=25, randomized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 8, 8, 0, 6, 6, 9, 6, 3, 1, 0, 9, 5, 7, 9, 6, 5, 9, 8, 6, 9, 0, 4, 9, 4, 6, 7, 0, 9, 6, 6, 5]\n",
      "[[3, 5], [8], [8, 0, 9], [0, 8], [6], [6], [9, 1, 7], [6, 2, 4, 3], [3, 5], [1, 9], [0, 5, 2, 3, 8], [9], [5, 4, 3, 6], [7, 5], [9], [6, 3], [5], [9, 7], [8, 9], [6], [9, 1, 7, 0], [0], [4, 2, 3, 5, 0, 6], [9], [4, 2], [6, 3, 2, 5, 4], [7, 5, 3, 2, 4], [0, 4, 7], [9], [6], [6, 2], [5, 3, 2]]\n",
      "0.6865367965367966\n"
     ]
    }
   ],
   "source": [
    "pred_set_loader = torch.utils.data.DataLoader(res[1], batch_size=32,shuffle=False, collate_fn=lambda x: x)\n",
    "# for x in pred_set_loader:\n",
    "#     print(x)\n",
    "#     break\n",
    "# print(res[1][0])\n",
    "for S, (_, y) in zip(pred_set_loader, test_loader):\n",
    "    top1s = []\n",
    "    [top1s.append(p_set[0]) for p_set in S]\n",
    "    S_tensor = [torch.tensor(sublist) for sublist in S]\n",
    "    cvg, sze = coverage_size(S_tensor, y)\n",
    "    f1 = f1_score(y_true=y.detach().cpu(),\n",
    "                    y_pred=top1s, average='macro', zero_division=0)\n",
    "    print(f1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8812899361022364, 2.1071285942492013, 0.65328483387119)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = validate_monte_carlo_prediction(val_loader=test_loader, predictions_sets=res[1])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [[3, 5], [8], [8, 0, 9], [0, 8], [6], [6], [9, 1, 7], [6, 2, 4, 3], [3, 5], [1, 9], [0, 5, 2, 3, 8], [9], [5, 4, 3, 6], [7, 5], [9], [6, 3], [5], [9, 7], [8, 9], [6], [9, 1, 7, 0], [0], [4, 2, 3, 5, 0, 6], [9], [4, 2], [6, 3, 2, 5, 4], [7, 5, 3, 2, 4], [0, 4, 7], [9], [6], [6, 2], [5, 3, 2]]\n",
    "l2 = [3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9, 5, 2, 4, 0, 9, 6, 6, 5]\n",
    "\n",
    "# Flatten l2\n",
    "def calculate_percentage(l1, l2):\n",
    "    c = 0\n",
    "    for sublist1, sublist2 in zip(l1, l2):\n",
    "        if  sublist2 in sublist1 : \n",
    "            c+=1\n",
    "    return c/len(l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_percentage(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d685bfd7114377445cb2c23cc6bfca7f1f2544957139cb4a27ccab868339e3e1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
