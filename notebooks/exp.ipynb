{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from src.data.make_cifar10_dataset import CIFAR10, get_img_transformer\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.models.cifar10_conv_model import Cifar10ConvModel\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import torch.nn.functional as nnf\n",
    "from skorch import NeuralNetClassifier\n",
    "from mapie.classification import MapieClassifier\n",
    "from mapie.metrics import (classification_coverage_score,\n",
    "                           classification_mean_width_score)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os.path\n",
    "import pickle\n",
    "import itertools\n",
    "import pathlib\n",
    "\n",
    "from src.utils.bootstrap_utils import train_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "test_dataset = CIFAR10(split=\"test\", root='../data/processed', download=True,\n",
    "                      transform=get_img_transformer())\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=len(test_dataset), drop_last=True)\n",
    "calib_dataset = CIFAR10(split=\"calib\", root='../data/processed', download=True,\n",
    "                      transform=get_img_transformer())\n",
    "calib_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=len(calib_dataset), drop_last=True)\n",
    "train_dataset = CIFAR10(split=\"train\", root='../data/processed', download=True,\n",
    "                      transform=get_img_transformer())\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=len(train_dataset))\n",
    "\n",
    "n_classes = len(set(test_dataset.targets))\n",
    "classes = {index: name for name, index in test_dataset.class_to_idx.items()}\n",
    "model = Cifar10ConvModel()\n",
    "# model.load_state_dict(torch.load(\"../models/trained_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"cifar-10-batches-py\"\n",
    "downloaded_list = [\n",
    "        [\"data_batch_1\", \"c99cafc152244af753f735de768cd75f\"],\n",
    "        [\"data_batch_2\", \"d4bba439e000b95fd0a9bffe97cbabec\"],\n",
    "        [\"data_batch_3\", \"54ebc095f3ab1f0389bbae665268c751\"],\n",
    "        [\"data_batch_4\", \"634d18415352ddfa80567beed471001a\"],\n",
    "    ]\n",
    "data =[]\n",
    "targets =[]\n",
    "for file_name, checksum in downloaded_list:\n",
    "    file_path = os.path.join(\"../data/processed\", base_folder, file_name)\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        entry = pickle.load(f, encoding=\"latin1\")\n",
    "        data.append(entry[\"data\"])\n",
    "        if \"labels\" in entry:\n",
    "            targets.extend(entry[\"labels\"])\n",
    "        else:\n",
    "            targets.extend(entry[\"fine_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    model,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = next(iter(train_dataloader))[0].numpy()\n",
    "y_train = next(iter(train_dataloader))[1].numpy()\n",
    "X_test = next(iter(test_dataloader))[0].numpy()\n",
    "y_test = next(iter(test_dataloader))[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_calib = next(iter(calib_dataloader))[0].numpy()\n",
    "y_calib = next(iter(calib_dataloader))[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Cifar10ConvModel(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "    (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (out): Linear(in_features=64, out_features=10, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6535"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.067634"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3, 32, 32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_calib.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(train_dataset.data, train_dataset.targets)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "y_pred_proba_max = np.max(y_pred_proba, axis=1)\n",
    "mapie_score = MapieClassifier(estimator=clf, cv=\"prefit\", method=\"score\")\n",
    "mapie_score.fit(X_calib, y_calib)\n",
    "# alpha = [0.2, 0.1, 0.05]\n",
    "# y_pred_score, y_ps_score = mapie_score.predict(X_test_mesh, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = torch.randn(100, 64, 1, 28, 28, device='cpu')\n",
    "min_batches = data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = torch.randint(2000, size=(1,)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_train_idx = np.random.choice(np.array(range(len(train_dataset))),replace=False, size=25600)\n",
    "train_subset = torch.utils.data.Subset(train_dataset, random_train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(train_subset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500     training accuracy: 0.734375\n",
      "Step 1000    training accuracy: 0.74703125\n",
      "Step 1500    training accuracy: 0.7454910714285714\n",
      "Step 2000    training accuracy: 0.756484375\n",
      "Step 2500    training accuracy: 0.7709375\n",
      "Step 3000    training accuracy: 0.76859375\n",
      "Step 3500    training accuracy: 0.780625\n",
      "Step 4000    training accuracy: 0.7759375\n",
      "Step 4500    training accuracy: 0.7911875\n",
      "Step 5000    training accuracy: 0.7925\n",
      "Step 5500    training accuracy: 0.7985267857142857\n",
      "Step 6000    training accuracy: 0.80453125\n",
      "Step 6500    training accuracy: 0.8084375\n",
      "Step 7000    training accuracy: 0.8199479166666667\n",
      "Step 7500    training accuracy: 0.8240625\n",
      "Step 8000    training accuracy: 0.81859375\n"
     ]
    }
   ],
   "source": [
    "train_classifier(model, dl, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dw/gf2x93p50fdd3796cx4grnqw0000gn/T/ipykernel_33835/121977584.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_classes' is not defined"
     ]
    }
   ],
   "source": [
    "def accuracy(target, pred):\n",
    "    return metrics.accuracy_score(target.detach().cpu().numpy(), pred.detach().cpu().numpy())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "confusion_matrix = np.zeros((n_classes, n_classes))\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_accuracies = []\n",
    "    for inputs, targets in test_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, targets)\n",
    "        print(inputs.shape)\n",
    "        predictions = output.max(1)[1]\n",
    "\n",
    "        # Multiply by len(inputs) because the final batch of DataLoader may be smaller (drop_last=True).\n",
    "        test_accuracies.append(accuracy(targets, predictions) * len(inputs))\n",
    "        \n",
    "        # confusion_matrix += compute_confusion_matrix(targets, predictions)\n",
    "\n",
    "    test_accuracy = np.sum(test_accuracies) / len(test_dataset)\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.680\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dw/gf2x93p50fdd3796cx4grnqw0000gn/T/ipykernel_50718/1741355202.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# data = torch.randn( 1, 3, 32, 32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# pred = get_ensemble_preparation(models, data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/DTU/b_thesis_project/classification-uncertainty-quantification/src/utils/bootstrap_utils.py\u001b[0m in \u001b[0;36mtrain_ensemble\u001b[0;34m(models, dataset, print_acc, num_epoches)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mtrain_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_train_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         train_classifier(model, dataloader, print_acc=True,\n\u001b[0m\u001b[1;32m     97\u001b[0m                          num_epoches=num_epoches)\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/DTU/b_thesis_project/classification-uncertainty-quantification/src/utils/bootstrap_utils.py\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(model, dataloader, print_acc, num_epoches)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mtrain_accuracies_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracies_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/DTU/b_thesis_project/classification-uncertainty-quantification/src/utils/bootstrap_utils.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(output, target, topk)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import axes\n",
    "from torch import batch_norm\n",
    "from src.utils.bootstrap_utils import get_ensemble_preparation, train_ensemble\n",
    "from src.models.cifar10_conv_model import Cifar10ConvModel\n",
    "train_set = CIFAR10(split='train', root='../data/processed', download=True,\n",
    "                       transform=get_img_transformer())\n",
    "models = [Cifar10ConvModel(), Cifar10ConvModel(), Cifar10ConvModel(), Cifar10ConvModel()]\n",
    "# train_ensemble(models, print_acc=True, num_epoches=1)\n",
    "# data = torch.randn( 1, 3, 32, 32)\n",
    "\n",
    "train_ensemble(models, train_set, num_epoches=4)\n",
    "# pred = get_ensemble_preparation(models, data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softvotes(probs):\n",
    "    sum_probs = torch.tensor([])\n",
    "    for pred_idx in range(probs.shape[1]):\n",
    "        pred_lis = torch.tensor([])\n",
    "        for model_prob in probs:\n",
    "            pred_lis = torch.cat((pred_lis, model_prob[pred_idx].unsqueeze(dim=0)))\n",
    "        sum_probs =torch.cat((sum_probs, torch.sum(pred_lis, dim=0).unsqueeze(dim=0)))\n",
    "    return sum_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].float().sum()\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from src.data.make_cifar10_dataset import CIFAR10, get_img_transformer\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "dataset = CIFAR10(split='test', root='../data/processed', download=True,\n",
    "                      transform=get_img_transformer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n",
      "0.59375\n",
      "0.875\n",
      "0.625\n",
      "0.875\n",
      "0.71875\n",
      "0.75\n",
      "0.59375\n",
      "0.59375\n",
      "0.65625\n",
      "0.78125\n",
      "0.875\n",
      "0.65625\n",
      "0.75\n",
      "0.65625\n",
      "0.59375\n",
      "0.78125\n",
      "0.71875\n",
      "0.75\n",
      "0.71875\n",
      "0.59375\n",
      "0.8125\n",
      "0.78125\n",
      "0.65625\n",
      "0.78125\n",
      "0.59375\n",
      "0.71875\n",
      "0.5625\n",
      "0.78125\n",
      "0.8125\n",
      "0.71875\n",
      "0.78125\n",
      "0.8125\n",
      "0.6875\n",
      "0.75\n",
      "0.59375\n",
      "0.78125\n",
      "0.84375\n",
      "0.84375\n",
      "0.8125\n",
      "0.75\n",
      "0.59375\n",
      "0.625\n",
      "0.75\n",
      "0.75\n",
      "0.71875\n",
      "0.875\n",
      "0.78125\n",
      "0.90625\n",
      "0.875\n",
      "0.59375\n",
      "0.6875\n",
      "0.78125\n",
      "0.78125\n",
      "0.53125\n",
      "0.75\n",
      "0.59375\n",
      "0.65625\n",
      "0.8125\n",
      "0.5625\n",
      "0.6875\n",
      "0.75\n",
      "0.8125\n",
      "0.5625\n",
      "0.78125\n",
      "0.6875\n",
      "0.5625\n",
      "0.78125\n",
      "0.78125\n",
      "0.8125\n",
      "0.65625\n",
      "0.5625\n",
      "0.84375\n",
      "0.75\n",
      "0.6875\n",
      "0.8125\n",
      "0.78125\n",
      "0.8125\n",
      "0.65625\n",
      "0.8125\n",
      "0.75\n",
      "0.75\n",
      "0.78125\n",
      "0.71875\n",
      "0.625\n",
      "0.6875\n",
      "0.8125\n",
      "0.71875\n",
      "0.78125\n",
      "0.75\n",
      "0.6875\n",
      "0.75\n",
      "0.75\n",
      "0.84375\n",
      "0.84375\n",
      "0.6875\n",
      "0.59375\n",
      "0.84375\n",
      "0.75\n",
      "0.65625\n",
      "0.78125\n",
      "0.65625\n",
      "0.8125\n",
      "0.75\n",
      "0.6875\n",
      "0.8125\n",
      "0.71875\n",
      "0.75\n",
      "0.6875\n",
      "0.84375\n",
      "0.75\n",
      "0.75\n",
      "0.75\n",
      "0.75\n",
      "0.875\n",
      "0.8125\n",
      "0.78125\n",
      "0.71875\n",
      "0.6875\n",
      "0.84375\n",
      "0.5625\n",
      "0.8125\n",
      "0.53125\n",
      "0.75\n",
      "0.8125\n",
      "0.71875\n",
      "0.6875\n",
      "0.6875\n",
      "0.625\n",
      "0.6875\n",
      "0.8125\n",
      "0.75\n",
      "0.75\n",
      "0.71875\n",
      "0.71875\n",
      "0.59375\n",
      "0.84375\n",
      "0.8125\n",
      "0.6875\n",
      "0.78125\n",
      "0.625\n",
      "0.625\n",
      "0.71875\n",
      "0.625\n",
      "0.78125\n",
      "0.8125\n",
      "0.6875\n",
      "0.71875\n",
      "0.75\n",
      "0.5625\n",
      "0.6875\n",
      "0.65625\n",
      "0.625\n",
      "0.65625\n",
      "0.625\n",
      "0.59375\n",
      "0.71875\n",
      "0.6875\n",
      "0.75\n",
      "0.65625\n",
      "0.5625\n",
      "0.875\n",
      "0.75\n",
      "0.75\n",
      "0.71875\n",
      "0.71875\n",
      "0.71875\n",
      "0.8125\n",
      "0.625\n",
      "0.75\n",
      "0.59375\n",
      "0.71875\n",
      "0.84375\n",
      "0.8125\n",
      "0.78125\n",
      "0.84375\n",
      "0.6875\n",
      "0.65625\n",
      "0.8125\n",
      "0.6875\n",
      "0.71875\n",
      "0.78125\n",
      "0.59375\n",
      "0.59375\n",
      "0.75\n",
      "0.71875\n",
      "0.71875\n",
      "0.6875\n",
      "0.71875\n",
      "0.59375\n",
      "0.65625\n",
      "0.78125\n",
      "0.75\n",
      "0.625\n",
      "0.75\n",
      "0.71875\n",
      "0.75\n",
      "0.65625\n",
      "0.5625\n",
      "0.6875\n",
      "0.78125\n",
      "0.71875\n",
      "0.75\n",
      "0.59375\n",
      "0.75\n",
      "0.8125\n",
      "0.65625\n",
      "0.71875\n",
      "0.75\n",
      "0.75\n",
      "0.78125\n",
      "0.65625\n",
      "0.71875\n",
      "0.65625\n",
      "0.71875\n",
      "0.78125\n",
      "0.75\n",
      "0.75\n",
      "0.71875\n",
      "0.75\n",
      "0.78125\n",
      "0.65625\n",
      "0.6875\n",
      "0.75\n",
      "0.6875\n",
      "0.59375\n",
      "0.78125\n",
      "0.75\n",
      "0.90625\n",
      "0.75\n",
      "0.8125\n",
      "0.625\n",
      "0.875\n",
      "0.71875\n",
      "0.71875\n",
      "0.65625\n",
      "0.6875\n",
      "0.59375\n",
      "0.625\n",
      "0.5625\n",
      "0.75\n",
      "0.65625\n",
      "0.6875\n",
      "0.59375\n",
      "0.90625\n",
      "0.75\n",
      "0.75\n",
      "0.75\n",
      "0.71875\n",
      "0.75\n",
      "0.71875\n",
      "0.59375\n",
      "0.625\n",
      "0.8125\n",
      "0.75\n",
      "0.8125\n",
      "0.75\n",
      "0.78125\n",
      "0.6875\n",
      "0.625\n",
      "0.71875\n",
      "0.71875\n",
      "0.78125\n",
      "0.8125\n",
      "0.65625\n",
      "0.71875\n",
      "0.59375\n",
      "0.78125\n",
      "0.625\n",
      "0.90625\n",
      "0.78125\n",
      "0.71875\n",
      "0.75\n",
      "0.78125\n",
      "0.71875\n",
      "0.75\n",
      "0.78125\n",
      "0.65625\n",
      "0.8125\n",
      "0.75\n",
      "0.75\n",
      "0.78125\n",
      "0.71875\n",
      "0.6875\n",
      "0.71875\n",
      "0.59375\n",
      "0.65625\n",
      "0.78125\n",
      "0.75\n",
      "0.6875\n",
      "0.71875\n",
      "0.71875\n",
      "0.71875\n",
      "0.78125\n",
      "0.6875\n",
      "0.71875\n",
      "0.8125\n",
      "0.8125\n",
      "0.75\n",
      "0.59375\n",
      "0.71875\n",
      "0.65625\n",
      "0.8125\n",
      "0.5625\n",
      "0.84375\n",
      "0.65625\n",
      "0.6875\n",
      "0.8125\n",
      "0.59375\n",
      "0.65625\n",
      "0.65625\n",
      "0.75\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "with torch.no_grad():\n",
    "    [model.eval() for model in models]\n",
    "    for inputs, targets in dataloader:\n",
    "        output = get_ensemble_preparation(models, inputs)\n",
    "        # print('output:')\n",
    "        # print(output.size())\n",
    "        probs = torch.stack([nnf.softmax(x, dim=1) for x in output])\n",
    "# validate shape and correctness\n",
    "        assert output.shape == probs.shape\n",
    "        assert torch.all(torch.eq(probs[0], nnf.softmax(output[0], dim=1))).item()\n",
    "\n",
    "        acc = accuracy(get_softvotes(probs), targets)[0].item()/100.0\n",
    "        print(acc)\n",
    "        # probs = np.array([nnf.softmax(x, dim=1).detach().numpy() for x in output])\n",
    "        \n",
    "        # sum_probs = np.sum(probs, axis=0)\n",
    "        # print(\"sum\")\n",
    "        # print(sum_probs)\n",
    "        # print(f\"prediction: {np.argmax(sum_probs)}\" )\n",
    "        # print(f\"target:{targets}\")\n",
    "        # print(f\"probs:\")\n",
    "        # print(probs)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.7948967e-05 2.7834473e-03 4.8145669e-04 ... 1.0736908e-05\n",
      "   4.9595234e-05 4.7396938e-03]\n",
      "  [3.9964016e-03 2.2137694e-03 9.9002190e-02 ... 5.3547500e-03\n",
      "   6.0709799e-03 2.2735300e-03]\n",
      "  [7.4287809e-02 5.0519593e-04 6.3119245e-01 ... 4.8127263e-03\n",
      "   3.9686598e-02 1.0570972e-03]\n",
      "  ...\n",
      "  [2.7672156e-06 1.4352670e-05 5.3852453e-04 ... 2.2338359e-07\n",
      "   1.4825059e-05 1.5478002e-04]\n",
      "  [6.1442150e-04 1.4444434e-07 8.1972891e-01 ... 8.6542146e-05\n",
      "   4.5060391e-05 6.9018142e-07]\n",
      "  [9.2804078e-07 9.9976152e-01 8.2217018e-11 ... 1.3848707e-12\n",
      "   6.8618983e-06 2.3074000e-04]]\n",
      "\n",
      " [[2.7701558e-04 2.8405702e-03 1.0112638e-02 ... 5.5235454e-05\n",
      "   4.9509935e-04 5.5824551e-03]\n",
      "  [5.9990771e-03 1.1627412e-03 7.9407595e-02 ... 7.9791958e-04\n",
      "   3.0931637e-03 3.2709162e-03]\n",
      "  [4.6678022e-03 1.1893477e-04 3.0543259e-01 ... 2.7741797e-03\n",
      "   4.2088074e-03 7.1993977e-04]\n",
      "  ...\n",
      "  [2.7674162e-06 2.0695081e-05 2.4089379e-04 ... 3.3351590e-08\n",
      "   1.1284867e-06 2.0651106e-04]\n",
      "  [1.2935445e-02 2.7627312e-08 9.4789755e-01 ... 1.1073803e-04\n",
      "   5.7120815e-05 5.7740533e-07]\n",
      "  [4.4379765e-05 9.9744844e-01 7.2511003e-10 ... 2.9846964e-10\n",
      "   9.0517016e-05 2.4167043e-03]]\n",
      "\n",
      " [[2.6247115e-05 3.4211607e-05 4.5389049e-03 ... 3.6754750e-06\n",
      "   1.9022678e-05 3.1554020e-05]\n",
      "  [3.4264051e-03 2.6891053e-02 4.5408744e-02 ... 1.9874067e-04\n",
      "   1.5680667e-02 6.9462135e-04]\n",
      "  [7.2455113e-03 1.6422429e-03 1.2930718e-01 ... 7.3534274e-03\n",
      "   1.2728887e-02 1.3100302e-03]\n",
      "  ...\n",
      "  [5.2533682e-08 1.8094597e-07 9.0305111e-06 ... 1.3000078e-11\n",
      "   1.1652589e-08 3.7749331e-07]\n",
      "  [1.9765301e-03 2.1861286e-08 9.5483780e-01 ... 2.4130937e-05\n",
      "   8.4944741e-06 1.3993312e-07]\n",
      "  [1.8924147e-05 9.9717605e-01 1.4101581e-06 ... 3.7031862e-07\n",
      "   1.5910211e-04 2.5888456e-03]]\n",
      "\n",
      " [[9.9539233e-05 2.1940558e-03 6.7666546e-03 ... 1.2151261e-05\n",
      "   1.3756577e-04 5.3570361e-04]\n",
      "  [2.5965521e-04 1.5057458e-05 5.2467372e-02 ... 9.0601601e-02\n",
      "   6.0665701e-05 7.1817922e-05]\n",
      "  [4.3027457e-03 2.6616803e-04 1.6588715e-01 ... 1.7507561e-02\n",
      "   5.4585785e-03 4.2585301e-04]\n",
      "  ...\n",
      "  [3.7689479e-05 5.1855517e-05 9.0813767e-03 ... 4.9941110e-07\n",
      "   1.9884972e-05 7.4993521e-05]\n",
      "  [2.2635367e-03 1.4449559e-07 8.9651412e-01 ... 1.1743013e-04\n",
      "   1.9371038e-04 1.8013500e-06]\n",
      "  [9.6269889e-07 9.9916971e-01 9.2541322e-11 ... 1.6896340e-12\n",
      "   4.9363661e-07 8.2894444e-04]]]\n"
     ]
    }
   ],
   "source": [
    "# print(output[0])\n",
    "# print(\"=====\")\n",
    "# probs = torch.tensor()\n",
    "\n",
    "\n",
    "\n",
    "# torch.eq(probs, output)\n",
    "# for x in output:\n",
    "    # nnf.softmax(x, dim=1)\n",
    "print(probs.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6953e-11, 1.5376e-15, 1.3729e-07, 5.9769e-10, 5.4542e-04, 4.7880e-06,\n",
       "         2.9039e-13, 9.9945e-01, 5.3623e-17, 1.1444e-11]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnf.softmax(torch.tensor([[-1.2971e+01, -2.2279e+01, -3.9716e+00, -9.4084e+00,  4.3156e+00,\n",
    "         -4.1985e-01, -1.7038e+01,  1.1829e+01, -2.5635e+01, -1.3364e+01]]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softvotes(probs):\n",
    "    sum_probs = torch.tensor([])\n",
    "    for pred_idx in range(probs.shape[1]):\n",
    "        pred_lis = torch.tensor([])\n",
    "        for model_prob in probs:\n",
    "            pred_lis = torch.cat((pred_lis, model_prob[pred_idx].unsqueeze(dim=0)))\n",
    "        sum_probs =torch.cat((sum_probs, torch.sum(pred_lis, dim=0).unsqueeze(dim=0)))\n",
    "    return sum_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    \n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].float().sum()\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2969e-01, 3.6828e-01, 2.4209e-01, 1.2599e+00, 8.8491e-02, 7.3073e-01,\n",
      "         2.6864e-01, 1.2785e-01, 2.9833e-01, 3.8602e-01],\n",
      "        [1.0330e-03, 3.8624e-04, 1.0482e-01, 4.8279e-01, 2.9720e-01, 2.5483e+00,\n",
      "         2.4274e-01, 3.2169e-01, 1.0723e-04, 9.1972e-04],\n",
      "        [2.1115e-04, 5.8661e-01, 1.1665e-07, 1.6987e-06, 1.9581e-09, 7.8862e-08,\n",
      "         1.8200e-06, 5.2618e-07, 1.4877e-05, 3.4132e+00],\n",
      "        [6.3916e-02, 4.5867e-04, 2.4714e+00, 5.4850e-01, 5.6941e-01, 2.3085e-01,\n",
      "         5.0071e-02, 5.0040e-02, 1.3901e-02, 1.4667e-03],\n",
      "        [3.5400e+00, 6.8625e-04, 1.8815e-02, 1.0720e-04, 1.5802e-03, 1.1556e-05,\n",
      "         2.9676e-05, 3.8793e-05, 4.3540e-01, 3.3648e-03],\n",
      "        [1.1054e-03, 2.8399e-04, 2.4528e-06, 1.8643e-05, 1.2702e-08, 1.1464e-05,\n",
      "         1.1113e-06, 5.7141e-05, 6.4715e-06, 3.9985e+00],\n",
      "        [2.4177e+00, 2.5023e-01, 3.5398e-01, 1.1592e-01, 3.9577e-01, 3.7699e-02,\n",
      "         2.3450e-02, 4.7116e-02, 3.3495e-01, 2.3146e-02],\n",
      "        [1.6973e-05, 3.9902e+00, 4.3435e-09, 6.2852e-08, 1.1268e-10, 1.0612e-08,\n",
      "         5.3836e-08, 2.4847e-09, 2.0826e-05, 9.7848e-03],\n",
      "        [3.9519e+00, 1.5434e-02, 4.4245e-03, 1.2091e-04, 1.1411e-02, 4.7773e-05,\n",
      "         9.7470e-06, 1.3381e-03, 3.3202e-03, 1.1959e-02],\n",
      "        [2.8919e-01, 2.1876e-01, 2.1986e-01, 8.1981e-01, 3.9276e-01, 3.2454e-01,\n",
      "         8.7126e-02, 2.8316e-01, 1.1569e-01, 1.2491e+00],\n",
      "        [4.7104e-02, 7.5751e-01, 8.0380e-05, 8.2981e-05, 1.3494e-05, 1.0399e-05,\n",
      "         4.5417e-05, 1.8395e-04, 2.0905e-02, 3.1741e+00],\n",
      "        [2.7151e+00, 1.4553e-01, 9.8554e-02, 3.6423e-02, 1.7032e-02, 1.9588e-02,\n",
      "         3.8485e-03, 3.0713e-02, 1.4543e-01, 7.8779e-01],\n",
      "        [7.3832e-05, 1.0589e-06, 5.1781e-02, 2.3479e-03, 3.9111e+00, 7.5363e-03,\n",
      "         1.2943e-02, 1.4237e-02, 3.2208e-06, 1.1790e-06],\n",
      "        [2.5699e-02, 2.1471e-03, 1.3893e-01, 1.0185e-01, 5.4123e-01, 1.8443e-01,\n",
      "         1.6193e-02, 2.9651e+00, 7.0095e-03, 1.7428e-02],\n",
      "        [2.5743e-02, 6.3401e-04, 1.1381e+00, 5.9455e-01, 1.2227e-01, 1.9135e+00,\n",
      "         7.4477e-02, 1.2155e-01, 6.1893e-03, 2.9549e-03],\n",
      "        [3.5459e-02, 1.5962e-03, 5.7977e-01, 2.9373e-01, 2.5499e+00, 2.8434e-01,\n",
      "         6.7892e-02, 1.7510e-01, 9.5649e-03, 2.6151e-03],\n",
      "        [1.3500e+00, 1.7903e-02, 3.0749e-02, 2.3171e-03, 1.7846e-02, 4.8351e-04,\n",
      "         8.8186e-04, 7.2806e-04, 2.5708e+00, 8.2877e-03],\n",
      "        [1.8023e-03, 3.9587e+00, 6.4658e-07, 3.3686e-07, 1.0529e-07, 2.6369e-07,\n",
      "         6.1428e-07, 2.0553e-07, 5.7263e-04, 3.8918e-02],\n",
      "        [7.7472e-03, 2.4996e-04, 7.1120e-01, 3.0145e-01, 2.0447e+00, 3.6353e-01,\n",
      "         4.2376e-01, 1.4435e-01, 2.0834e-03, 9.5638e-04],\n",
      "        [3.0545e-02, 7.2302e-04, 8.1501e-04, 1.0031e-03, 1.5537e-04, 1.6601e-04,\n",
      "         3.7748e-05, 5.4749e-05, 3.9632e+00, 3.2773e-03],\n",
      "        [1.6857e+00, 2.8077e-02, 1.7475e-01, 2.4361e-01, 3.0292e-02, 1.0105e-01,\n",
      "         1.6015e-02, 2.0172e-02, 1.6770e+00, 2.3341e-02],\n",
      "        [9.6283e-02, 2.0099e-03, 2.2120e+00, 8.6746e-02, 4.1801e-01, 3.2200e-02,\n",
      "         1.1307e+00, 1.8581e-03, 1.9505e-02, 6.5867e-04],\n",
      "        [7.9932e-02, 1.7229e-03, 7.2168e-01, 1.8601e+00, 5.1388e-02, 7.7325e-01,\n",
      "         4.3848e-01, 3.0650e-02, 3.1366e-02, 1.1471e-02],\n",
      "        [1.9015e+00, 2.1288e-02, 1.5703e-01, 8.4346e-01, 1.1202e-02, 1.9171e-01,\n",
      "         2.8198e-01, 1.2261e-02, 3.3698e-01, 2.4259e-01],\n",
      "        [9.3389e-02, 1.2416e-01, 1.5635e-02, 6.8855e-02, 3.3696e-02, 4.1938e-02,\n",
      "         2.3207e-02, 1.7172e-01, 4.7567e-03, 3.4226e+00],\n",
      "        [1.9438e-03, 6.2535e-06, 1.9762e+00, 7.5606e-02, 1.6213e+00, 1.9623e-01,\n",
      "         1.1725e-01, 1.1338e-02, 4.7230e-05, 1.6469e-05],\n",
      "        [3.7791e-02, 1.4166e-02, 3.5469e-01, 1.1565e+00, 6.3205e-01, 1.1329e+00,\n",
      "         2.7036e-01, 3.6158e-01, 1.5189e-02, 2.4827e-02],\n",
      "        [8.7931e-01, 2.7109e-05, 1.0811e-01, 1.6522e-03, 2.9024e+00, 4.4518e-03,\n",
      "         1.0656e-03, 1.0275e-01, 2.0107e-04, 2.8011e-05],\n",
      "        [8.7678e-04, 9.4510e-06, 3.4990e-01, 1.3109e-01, 2.3122e+00, 4.3126e-01,\n",
      "         1.1688e-02, 7.6281e-01, 5.5526e-05, 1.2579e-04],\n",
      "        [1.1242e-01, 9.8629e-02, 1.5922e-01, 5.7099e-01, 2.3543e-01, 3.6727e-01,\n",
      "         8.0266e-02, 9.1778e-01, 2.6536e-01, 1.1926e+00],\n",
      "        [2.6919e-02, 7.0309e-04, 1.0317e+00, 4.7712e-01, 1.6566e+00, 5.1686e-01,\n",
      "         5.7263e-02, 2.2439e-01, 6.1101e-03, 2.3190e-03],\n",
      "        [5.8509e-03, 3.5999e-09, 3.9011e+00, 1.2144e-03, 8.2278e-02, 4.4806e-04,\n",
      "         9.1244e-03, 3.8418e-06, 2.5122e-05, 3.9557e-08]])\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(get_softvotes(), targets)[0].item()/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dw/gf2x93p50fdd3796cx4grnqw0000gn/T/ipykernel_50718/4091113619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "str(pathlib.Path(__file__).parent.absolute()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d685bfd7114377445cb2c23cc6bfca7f1f2544957139cb4a27ccab868339e3e1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
